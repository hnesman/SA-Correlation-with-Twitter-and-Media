{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# \n",
    "import pandas as pd\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LosAndes = pd.read_csv('/users/hnesman/Downloads/DATA_Science/LosAndes.csv')\n",
    "LosAndes_1 = pd.read_csv('/users/hnesman/Downloads/DATA_Science/LosAndes_1.csv')\n",
    "LaNacion = pd.read_csv('/users/hnesman/Downloads/DATA_Science/LaNacion.csv')\n",
    "LaVoz = pd.read_csv('/users/hnesman/Downloads/DATA_Science/LaVoz.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MediaNews = pd.concat([LosAndes,LaNacion])\n",
    "MediaNews = pd.concat([LosAndes_1,MediaNews])\n",
    "MediaNews = pd.concat([LaVoz,MediaNews])\n",
    "MediaNews = MediaNews.drop('Unnamed: 0',axis=1)\n",
    "MediaNews.columns = ['Date', 'Title', 'Encabezado', 'Article Label', 'Media']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Encabezado</th>\n",
       "      <th>Article Label</th>\n",
       "      <th>Media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30/04/2017</td>\n",
       "      <td>la oposicion venezolana vuelve las calles</td>\n",
       "      <td>la oposicion venezolana vuelve las calles</td>\n",
       "      <td>mundo</td>\n",
       "      <td>La Voz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30/04/2017</td>\n",
       "      <td>una reparacion demasiado lenta</td>\n",
       "      <td>una reparacion demasiado lenta</td>\n",
       "      <td>editorial</td>\n",
       "      <td>La Voz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30/04/2017</td>\n",
       "      <td>precios la canasta hasta 900 mas cara segun el...</td>\n",
       "      <td>precios la canasta hasta 900 mas cara segun el...</td>\n",
       "      <td>ciudadanos</td>\n",
       "      <td>La Voz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30/04/2017</td>\n",
       "      <td>gasoductos 760 millones gastados la espera de ...</td>\n",
       "      <td>gasoductos 760 millones gastados la espera de ...</td>\n",
       "      <td>politica</td>\n",
       "      <td>La Voz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30/04/2017</td>\n",
       "      <td>noelia mi ex quiso asesinarme le preguntaria p...</td>\n",
       "      <td>noelia mi ex quiso asesinarme le preguntaria p...</td>\n",
       "      <td>sucesos</td>\n",
       "      <td>La Voz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                              Title  \\\n",
       "0  30/04/2017          la oposicion venezolana vuelve las calles   \n",
       "1  30/04/2017                     una reparacion demasiado lenta   \n",
       "2  30/04/2017  precios la canasta hasta 900 mas cara segun el...   \n",
       "3  30/04/2017  gasoductos 760 millones gastados la espera de ...   \n",
       "4  30/04/2017  noelia mi ex quiso asesinarme le preguntaria p...   \n",
       "\n",
       "                                          Encabezado Article Label   Media  \n",
       "0          la oposicion venezolana vuelve las calles         mundo  La Voz  \n",
       "1                     una reparacion demasiado lenta     editorial  La Voz  \n",
       "2  precios la canasta hasta 900 mas cara segun el...    ciudadanos  La Voz  \n",
       "3  gasoductos 760 millones gastados la espera de ...      politica  La Voz  \n",
       "4  noelia mi ex quiso asesinarme le preguntaria p...       sucesos  La Voz  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MediaNews.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MediaNews.to_csv('/users/hnesman/Downloads/DATA_Science/MediaNews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "# import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "After pruning, no terms remain. Try a lower min_df or a higher max_df.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5bd974a1c0c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# Build a mapping of numerical ID to word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mid2word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hnesman/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    858\u001b[0m                                                        \u001b[0mmax_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m                                                        \u001b[0mmin_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m                                                        max_features)\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hnesman/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_limit_features\u001b[0;34m(self, X, vocabulary, high, low, limit)\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0mkept_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkept_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m             raise ValueError(\"After pruning, no terms remain. Try a lower\"\n\u001b[0m\u001b[1;32m    742\u001b[0m                              \" min_df or a higher max_df.\")\n\u001b[1;32m    743\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkept_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremoved_terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: After pruning, no terms remain. Try a lower min_df or a higher max_df."
     ]
    }
   ],
   "source": [
    "#I will start analyzing the data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data = pd.read_csv('/users/hnesman/Downloads/DATA_Science/MediaNews.csv', sep=',')\n",
    "\n",
    "cv = CountVectorizer(binary=False,min_df=2)\n",
    "test = data\n",
    "\n",
    "docs = cv.fit_transform(data)\n",
    "# Build a mapping of numerical ID to word\n",
    "id2word = dict(enumerate(cv.get_feature_names()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
